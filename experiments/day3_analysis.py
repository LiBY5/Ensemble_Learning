"""ç¬¬ä¸‰å¤©å®éªŒç»“æœæ·±åº¦åˆ†ææ¨¡å—"""
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.gridspec import GridSpec
import warnings
import os

warnings.filterwarnings('ignore')


class Day3ResultsAnalyzer:
    """ç¬¬ä¸‰å¤©å®éªŒç»“æœåˆ†æå™¨"""

    def __init__(self, results_dir='../results'):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        å‚æ•°:
        ----------
        results_dir : str, ç»“æœç›®å½•
        """
        self.results_dir = results_dir
        self.regression_results = None
        self.classification_results = None
        self.setup_visualization()

    def setup_visualization(self):
        """è®¾ç½®å¯è§†åŒ–æ ·å¼"""
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        plt.rcParams['figure.figsize'] = (12, 8)
        plt.style.use('seaborn-v0_8-darkgrid')

        # è®¾ç½®é¢œè‰²ä¸»é¢˜
        self.colors = {
            'our_implementation': '#2E86AB',  # è“è‰²
            'sklearn': '#A23B72',  # ç´«è‰²
            'baseline': '#F18F01',  # æ©™è‰²
            'bagging': '#73AB84',  # ç»¿è‰²
            'random_forest': '#5B4B49',  # æ£•è‰²
            'adaboost': '#C73E1D',  # çº¢è‰²
            'gbdt': '#3A5A40'  # æ·±ç»¿
        }

    def load_results(self):
        """åŠ è½½å®éªŒç»“æœ"""
        print("=" * 60)
        print("åŠ è½½ç¬¬ä¸‰å¤©å®éªŒç»“æœ")
        print("=" * 60)

        # åŠ è½½å›å½’ç»“æœ
        regression_path = '../results/logs/day3_regression_comparison.csv'
        if not os.path.exists(regression_path):
            raise FileNotFoundError(f"å›å½’ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {regression_path}")

        self.regression_results = pd.read_csv(regression_path)
        print(f"âœ… åŠ è½½å›å½’ç»“æœ: {len(self.regression_results)} ä¸ªæ¨¡å‹")

        # åŠ è½½åˆ†ç±»ç»“æœ
        classification_path = '../results/logs/day3_classification_comparison.csv'
        if not os.path.exists(classification_path):
            raise FileNotFoundError(f"åˆ†ç±»ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {classification_path}")

        self.classification_results = pd.read_csv(classification_path)
        print(f"âœ… åŠ è½½åˆ†ç±»ç»“æœ: {len(self.classification_results)} ä¸ªæ¨¡å‹")

        return self.regression_results, self.classification_results

    def analyze_regression_results(self):
        """æ·±åº¦åˆ†æå›å½’ç»“æœ"""
        if self.regression_results is None:
            self.load_results()

        print("\n" + "=" * 60)
        print("å›å½’ä»»åŠ¡æ·±åº¦åˆ†æ")
        print("=" * 60)

        # åˆ›å»ºåˆ†ææŠ¥å‘Š
        analysis_report = {
            'best_model': None,
            'key_insights': [],
            'comparisons': {},
            'recommendations': []
        }

        # 1. æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_mse_idx = self.regression_results['MSE'].idxmin()
        best_r2_idx = self.regression_results['RÂ²'].idxmax()
        best_composite_idx = self.regression_results['Composite_Score'].idxmax()

        best_mse_model = self.regression_results.loc[best_mse_idx, 'Model']
        best_r2_model = self.regression_results.loc[best_r2_idx, 'Model']
        best_composite_model = self.regression_results.loc[best_composite_idx, 'Model']

        print(f"ğŸ“Š æœ€ä½³MSEæ¨¡å‹: {best_mse_model} (MSE: {self.regression_results.loc[best_mse_idx, 'MSE']:.4f})")
        print(f"ğŸ“ˆ æœ€ä½³RÂ²æ¨¡å‹: {best_r2_model} (RÂ²: {self.regression_results.loc[best_r2_idx, 'RÂ²']:.4f})")
        print(
            f"ğŸ† ç»¼åˆæœ€ä½³æ¨¡å‹: {best_composite_model} (è¯„åˆ†: {self.regression_results.loc[best_composite_idx, 'Composite_Score']:.4f})")

        analysis_report['best_model'] = {
            'by_mse': best_mse_model,
            'by_r2': best_r2_model,
            'composite': best_composite_model
        }

        # 2. æ€§èƒ½å¯¹æ¯”åˆ†æ
        print("\nğŸ” æ€§èƒ½å¯¹æ¯”åˆ†æ:")

        # æˆ‘ä»¬çš„å®ç° vs sklearn
        our_gbdt = self.regression_results[self.regression_results['Model'] == 'GBDT (æˆ‘ä»¬çš„å®ç°)']
        sklearn_gbdt = self.regression_results[self.regression_results['Model'] == 'GBDT (sklearn)']

        if len(our_gbdt) > 0 and len(sklearn_gbdt) > 0:
            our_mse = our_gbdt['MSE'].values[0]
            sklearn_mse = sklearn_gbdt['MSE'].values[0]
            mse_diff = ((our_mse - sklearn_mse) / sklearn_mse) * 100

            our_r2 = our_gbdt['RÂ²'].values[0]
            sklearn_r2 = sklearn_gbdt['RÂ²'].values[0]
            r2_diff = ((our_r2 - sklearn_r2) / sklearn_r2) * 100

            print(f"  GBDTå¯¹æ¯” (æˆ‘ä»¬çš„å®ç° vs sklearn):")
            print(f"    MSEå·®å¼‚: {mse_diff:.2f}% (æˆ‘ä»¬çš„{'é«˜' if mse_diff > 0 else 'ä½'})")
            print(f"    RÂ²å·®å¼‚: {r2_diff:.2f}% (æˆ‘ä»¬çš„{'é«˜' if r2_diff > 0 else 'ä½'})")
            print(
                f"    è®­ç»ƒæ—¶é—´: {our_gbdt['Train_Time'].values[0]:.3f}s vs {sklearn_gbdt['Train_Time'].values[0]:.3f}s")

            analysis_report['comparisons']['gbdt_vs_sklearn'] = {
                'mse_difference_percent': mse_diff,
                'r2_difference_percent': r2_diff,
                'training_time_ratio': our_gbdt['Train_Time'].values[0] / sklearn_gbdt['Train_Time'].values[0]
            }

        # 3. è®¡ç®—æ”¹è¿›å¹…åº¦
        baseline_mse = self.regression_results[self.regression_results['Model'] == 'å†³ç­–æ ‘ (åŸºçº¿)']['MSE'].values[0]
        best_mse = self.regression_results['MSE'].min()
        improvement = (1 - best_mse / baseline_mse) * 100

        print(f"\nğŸš€ ç›¸å¯¹åŸºçº¿æ”¹è¿›:")
        print(f"  æœ€ä½³MSEç›¸å¯¹åŸºçº¿æ”¹è¿›: {improvement:.1f}%")
        print(
            f"  æœ€ä½³RÂ²ç›¸å¯¹åŸºçº¿æ”¹è¿›: {(self.regression_results['RÂ²'].max() - self.regression_results[self.regression_results['Model'] == 'å†³ç­–æ ‘ (åŸºçº¿)']['RÂ²'].values[0]) * 100:.1f}%")

        analysis_report['improvements'] = {
            'mse_improvement_percent': improvement,
            'baseline_mse': baseline_mse,
            'best_mse': best_mse
        }

        # 4. è®­ç»ƒæ•ˆç‡åˆ†æ
        print("\nâ±ï¸ è®­ç»ƒæ•ˆç‡åˆ†æ:")

        # è®¡ç®—ç²¾åº¦-æ•ˆç‡å¹³è¡¡
        self.regression_results['Efficiency_Score'] = (
                                                              (1 / self.regression_results['Train_Time']) * 0.3 +
                                                              (1 / self.regression_results['MSE']) * 0.7
                                                      ) * 100

        # å½’ä¸€åŒ–
        self.regression_results['Efficiency_Score'] = (
                                                              self.regression_results['Efficiency_Score'] -
                                                              self.regression_results['Efficiency_Score'].min()
                                                      ) / (
                                                              self.regression_results['Efficiency_Score'].max() -
                                                              self.regression_results['Efficiency_Score'].min()
                                                      )

        best_efficiency_idx = self.regression_results['Efficiency_Score'].idxmax()
        best_efficiency_model = self.regression_results.loc[best_efficiency_idx, 'Model']
        print(
            f"  æœ€ä½³æ•ˆç‡æ¨¡å‹: {best_efficiency_model} (æ•ˆç‡è¯„åˆ†: {self.regression_results.loc[best_efficiency_idx, 'Efficiency_Score']:.4f})")

        analysis_report['efficiency_analysis'] = {
            'best_efficiency_model': best_efficiency_model,
            'efficiency_scores': dict(zip(
                self.regression_results['Model'],
                self.regression_results['Efficiency_Score']
            ))
        }

        return analysis_report

    def analyze_classification_results(self):
        """æ·±åº¦åˆ†æåˆ†ç±»ç»“æœ"""
        if self.classification_results is None:
            self.load_results()

        print("\n" + "=" * 60)
        print("åˆ†ç±»ä»»åŠ¡æ·±åº¦åˆ†æ")
        print("=" * 60)

        analysis_report = {
            'best_model': None,
            'key_insights': [],
            'comparisons': {},
            'recommendations': []
        }

        # 1. æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_acc_idx = self.classification_results['Accuracy'].idxmax()
        best_auc_idx = self.classification_results['AUC'].dropna().idxmax() if self.classification_results[
            'AUC'].notna().any() else None
        best_composite_idx = self.classification_results['Composite_Score'].idxmax()

        best_acc_model = self.classification_results.loc[best_acc_idx, 'Model']
        best_composite_model = self.classification_results.loc[best_composite_idx, 'Model']

        print(
            f"ğŸ“Š æœ€ä½³å‡†ç¡®ç‡æ¨¡å‹: {best_acc_model} (å‡†ç¡®ç‡: {self.classification_results.loc[best_acc_idx, 'Accuracy']:.4f})")

        if best_auc_idx is not None:
            best_auc_model = self.classification_results.loc[best_auc_idx, 'Model']
            print(f"ğŸ“ˆ æœ€ä½³AUCæ¨¡å‹: {best_auc_model} (AUC: {self.classification_results.loc[best_auc_idx, 'AUC']:.4f})")

        print(
            f"ğŸ† ç»¼åˆæœ€ä½³æ¨¡å‹: {best_composite_model} (è¯„åˆ†: {self.classification_results.loc[best_composite_idx, 'Composite_Score']:.4f})")

        analysis_report['best_model'] = {
            'by_accuracy': best_acc_model,
            'by_composite': best_composite_model
        }

        if best_auc_idx is not None:
            analysis_report['best_model']['by_auc'] = self.classification_results.loc[best_auc_idx, 'Model']

        # 2. ç¨³å®šæ€§åˆ†æï¼ˆäº¤å‰éªŒè¯æ ‡å‡†å·®ï¼‰
        most_stable_idx = self.classification_results['CV_Std'].idxmin()
        most_stable_model = self.classification_results.loc[most_stable_idx, 'Model']
        print(
            f"\nğŸ¯ æœ€ç¨³å®šæ¨¡å‹: {most_stable_model} (CVæ ‡å‡†å·®: {self.classification_results.loc[most_stable_idx, 'CV_Std']:.4f})")

        # 3. è®­ç»ƒæ•ˆç‡åˆ†æ
        fastest_idx = self.classification_results['Train_Time'].idxmin()
        fastest_model = self.classification_results.loc[fastest_idx, 'Model']
        print(
            f"âš¡ æœ€å¿«è®­ç»ƒæ¨¡å‹: {fastest_model} (è®­ç»ƒæ—¶é—´: {self.classification_results.loc[fastest_idx, 'Train_Time']:.3f}s)")

        # 4. æˆ‘ä»¬çš„å®ç° vs sklearn
        print("\nğŸ” æˆ‘ä»¬çš„å®ç° vs sklearnå¯¹æ¯”:")

        # AdaBoostå¯¹æ¯”
        our_adaboost = self.classification_results[self.classification_results['Model'] == 'AdaBoost (æˆ‘ä»¬çš„å®ç°)']
        sklearn_adaboost = self.classification_results[self.classification_results['Model'] == 'AdaBoost (sklearn)']

        if len(our_adaboost) > 0 and len(sklearn_adaboost) > 0:
            acc_diff = (our_adaboost['Accuracy'].values[0] - sklearn_adaboost['Accuracy'].values[0]) * 100
            print(f"  AdaBoostå‡†ç¡®ç‡å·®å¼‚: {acc_diff:.2f}% (æˆ‘ä»¬çš„{'é«˜' if acc_diff > 0 else 'ä½'})")

            analysis_report['comparisons']['adaboost_vs_sklearn'] = {
                'accuracy_difference_percent': acc_diff
            }

        # GBDTå¯¹æ¯”
        our_gbdt = self.classification_results[self.classification_results['Model'] == 'GBDT (æˆ‘ä»¬çš„å®ç°)']
        sklearn_gbdt = self.classification_results[self.classification_results['Model'] == 'GBDT (sklearn)']

        if len(our_gbdt) > 0 and len(sklearn_gbdt) > 0:
            acc_diff = (our_gbdt['Accuracy'].values[0] - sklearn_gbdt['Accuracy'].values[0]) * 100
            print(f"  GBDTå‡†ç¡®ç‡å·®å¼‚: {acc_diff:.2f}% (æˆ‘ä»¬çš„{'é«˜' if acc_diff > 0 else 'ä½'})")

            analysis_report['comparisons']['gbdt_vs_sklearn'] = {
                'accuracy_difference_percent': acc_diff
            }

        return analysis_report

    def create_comprehensive_visualization(self):
        """åˆ›å»ºç»¼åˆå¯è§†åŒ–æŠ¥å‘Š"""
        fig = plt.figure(figsize=(20, 16))
        gs = GridSpec(4, 4, figure=fig, hspace=0.4, wspace=0.3)

        # 1. å›å½’ä»»åŠ¡MSEå¯¹æ¯”ï¼ˆå·¦ä¸Šï¼‰
        ax1 = fig.add_subplot(gs[0, :2])
        self._plot_regression_mse_comparison(ax1)

        # 2. å›å½’ä»»åŠ¡RÂ²å¯¹æ¯”ï¼ˆå³ä¸Šï¼‰
        ax2 = fig.add_subplot(gs[0, 2:])
        self._plot_regression_r2_comparison(ax2)

        # 3. åˆ†ç±»ä»»åŠ¡å‡†ç¡®ç‡å¯¹æ¯”ï¼ˆä¸­å·¦ï¼‰
        ax3 = fig.add_subplot(gs[1, :2])
        self._plot_classification_accuracy_comparison(ax3)

        # 4. è®­ç»ƒæ—¶é—´å¯¹æ¯”ï¼ˆä¸­å³ï¼‰
        ax4 = fig.add_subplot(gs[1, 2:])
        self._plot_training_time_comparison(ax4)

        # 5. æ¨¡å‹æ•ˆç‡é›·è¾¾å›¾ï¼ˆä¸‹å·¦ï¼‰
        ax5 = fig.add_subplot(gs[2, :2], projection='polar')
        self._plot_efficiency_radar(ax5)

        # 6. æ”¹è¿›å¹…åº¦å±•ç¤ºï¼ˆä¸‹å³ï¼‰
        ax6 = fig.add_subplot(gs[2, 2:])
        self._plot_improvement_summary(ax6)

        # 7. æ–‡æœ¬æ€»ç»“ï¼ˆåº•éƒ¨ï¼‰
        ax7 = fig.add_subplot(gs[3, :])
        ax7.axis('off')
        self._add_text_summary(ax7)

        plt.suptitle('ç¬¬ä¸‰å¤©ï¼šé›†æˆå­¦ä¹ æ–¹æ³•ç»¼åˆå®éªŒåˆ†ææŠ¥å‘Š', fontsize=20, fontweight='bold', y=0.98)
        plt.tight_layout()

        # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
        save_dir = f'{self.results_dir}/figures'
        os.makedirs(save_dir, exist_ok=True)

        plt.savefig(f'{save_dir}/day3_comprehensive_analysis.png',
                    dpi=150, bbox_inches='tight')
        plt.show()

        return fig

    def _plot_regression_mse_comparison(self, ax):
        """ç»˜åˆ¶å›å½’MSEå¯¹æ¯”å›¾"""
        if self.regression_results is None:
            return

        models = self.regression_results['Model']
        mse_values = self.regression_results['MSE']

        # è®¾ç½®é¢œè‰²
        colors = []
        for model in models:
            if 'æˆ‘ä»¬çš„å®ç°' in model:
                colors.append(self.colors['our_implementation'])
            elif 'sklearn' in model:
                colors.append(self.colors['sklearn'])
            elif 'åŸºçº¿' in model:
                colors.append(self.colors['baseline'])
            elif 'Bagging' in model:
                colors.append(self.colors['bagging'])
            elif 'éšæœºæ£®æ—' in model:
                colors.append(self.colors['random_forest'])
            elif 'AdaBoost' in model:
                colors.append(self.colors['adaboost'])
            elif 'GBDT' in model:
                colors.append(self.colors['gbdt'])
            else:
                colors.append('gray')

        bars = ax.barh(range(len(models)), mse_values, color=colors, edgecolor='black')
        ax.set_yticks(range(len(models)))
        ax.set_yticklabels(models)
        ax.set_xlabel('MSE (è¶Šå°è¶Šå¥½)', fontsize=12)
        ax.set_title('å›å½’ä»»åŠ¡MSEå¯¹æ¯”', fontsize=14, fontweight='bold')
        ax.invert_yaxis()
        ax.grid(True, alpha=0.3, axis='x')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, mse) in enumerate(zip(bars, mse_values)):
            ax.text(mse + 50, i, f'{mse:.1f}', va='center', fontsize=10)

    def _plot_regression_r2_comparison(self, ax):
        """ç»˜åˆ¶å›å½’RÂ²å¯¹æ¯”å›¾"""
        if self.regression_results is None:
            return

        models = self.regression_results['Model']
        r2_values = self.regression_results['RÂ²']

        colors = []
        for model in models:
            if 'æˆ‘ä»¬çš„å®ç°' in model:
                colors.append(self.colors['our_implementation'])
            elif 'sklearn' in model:
                colors.append(self.colors['sklearn'])
            else:
                colors.append('lightgray')

        bars = ax.bar(range(len(models)), r2_values, color=colors, edgecolor='black')
        ax.set_xticks(range(len(models)))
        ax.set_xticklabels(models, rotation=45, ha='right', fontsize=10)
        ax.set_ylabel('RÂ² (è¶Šå¤§è¶Šå¥½)', fontsize=12)
        ax.set_title('å›å½’ä»»åŠ¡RÂ²å¯¹æ¯”', fontsize=14, fontweight='bold')
        ax.set_ylim(0, 1)
        ax.grid(True, alpha=0.3, axis='y')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, r2 in zip(bars, r2_values):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width() / 2, height + 0.01,
                    f'{r2:.4f}', ha='center', va='bottom', fontsize=9)

    def _plot_classification_accuracy_comparison(self, ax):
        """ç»˜åˆ¶åˆ†ç±»å‡†ç¡®ç‡å¯¹æ¯”å›¾"""
        if self.classification_results is None:
            return

        models = self.classification_results['Model']
        accuracy = self.classification_results['Accuracy']

        colors = []
        for model in models:
            if 'æˆ‘ä»¬çš„å®ç°' in model:
                colors.append(self.colors['our_implementation'])
            elif 'sklearn' in model:
                colors.append(self.colors['sklearn'])
            elif 'åŸºçº¿' in model:
                colors.append(self.colors['baseline'])
            elif 'Bagging' in model:
                colors.append(self.colors['bagging'])
            elif 'éšæœºæ£®æ—' in model:
                colors.append(self.colors['random_forest'])
            elif 'AdaBoost' in model:
                colors.append(self.colors['adaboost'])
            elif 'GBDT' in model:
                colors.append(self.colors['gbdt'])
            else:
                colors.append('gray')

        bars = ax.bar(range(len(models)), accuracy, color=colors, edgecolor='black')
        ax.set_xticks(range(len(models)))
        ax.set_xticklabels(models, rotation=45, ha='right', fontsize=10)
        ax.set_ylabel('å‡†ç¡®ç‡', fontsize=12)
        ax.set_title('åˆ†ç±»ä»»åŠ¡å‡†ç¡®ç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
        ax.set_ylim(0.85, 1.0)
        # è®¾ç½®å­—ä½“ä¸ºç³»ç»Ÿè‡ªå¸¦çš„ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'KaiTi', 'FangSong']  # è®¾ç½®ä¸­æ–‡å­—ä½“
        # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
        plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜
        ax.grid(True, alpha=0.3, axis='y')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, acc in zip(bars, accuracy):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width() / 2, height + 0.003,
                    f'{acc:.4f}', ha='center', va='bottom', fontsize=9)

    def _plot_training_time_comparison(self, ax):
        """ç»˜åˆ¶è®­ç»ƒæ—¶é—´å¯¹æ¯”å›¾"""
        if self.regression_results is None or self.classification_results is None:
            return

        # åˆå¹¶å›å½’å’Œåˆ†ç±»çš„è®­ç»ƒæ—¶é—´
        models = []
        times = []
        categories = []

        # å›å½’æ¨¡å‹
        for _, row in self.regression_results.iterrows():
            models.append(row['Model'])
            times.append(row['Train_Time'])
            categories.append('å›å½’')

        # åˆ†ç±»æ¨¡å‹
        for _, row in self.classification_results.iterrows():
            models.append(row['Model'])
            times.append(row['Train_Time'])
            categories.append('åˆ†ç±»')

        # åˆ›å»ºDataFrame
        df = pd.DataFrame({
            'Model': models,
            'Time': times,
            'Category': categories
        })

        # ç»˜åˆ¶åˆ†ç»„æŸ±çŠ¶å›¾
        pivot_df = df.pivot(index='Model', columns='Category', values='Time')
        pivot_df.plot(kind='bar', ax=ax, color=['lightblue', 'lightcoral'], edgecolor='black')

        ax.set_xlabel('æ¨¡å‹', fontsize=12)
        ax.set_ylabel('è®­ç»ƒæ—¶é—´ (ç§’)', fontsize=12)
        ax.set_title('è®­ç»ƒæ—¶é—´å¯¹æ¯” (å›å½’ vs åˆ†ç±»)', fontsize=14, fontweight='bold')
        ax.legend(title='ä»»åŠ¡ç±»å‹')
        ax.grid(True, alpha=0.3, axis='y')
        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right', fontsize=9)

    def _plot_efficiency_radar(self, ax):
        """ç»˜åˆ¶æ¨¡å‹æ•ˆç‡é›·è¾¾å›¾"""
        if self.regression_results is None or self.classification_results is None:
            return

        # é€‰æ‹©å‡ ä¸ªå…³é”®æ¨¡å‹
        key_models = ['å†³ç­–æ ‘ (åŸºçº¿)', 'éšæœºæ£®æ—', 'AdaBoost (æˆ‘ä»¬çš„å®ç°)', 'GBDT (æˆ‘ä»¬çš„å®ç°)']

        # åˆ›å»ºé›·è¾¾å›¾æŒ‡æ ‡
        categories = ['å‡†ç¡®ç‡', 'RÂ²', 'è®­ç»ƒé€Ÿåº¦', 'ç¨³å®šæ€§', 'ç»¼åˆè¯„åˆ†']
        N = len(categories)

        # è®¡ç®—è§’åº¦
        angles = [n / float(N) * 2 * np.pi for n in range(N)]
        angles += angles[:1]  # é—­åˆ

        # è®¾ç½®é›·è¾¾å›¾
        ax.set_theta_offset(np.pi / 2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(categories, fontsize=11)

        # ç»˜åˆ¶æ¯ä¸ªæ¨¡å‹
        for i, model_name in enumerate(key_models):
            values = []

            # è·å–æ¨¡å‹æ•°æ®
            if model_name in self.regression_results['Model'].values:
                reg_data = self.regression_results[self.regression_results['Model'] == model_name].iloc[0]
                values.append(0.5)  # å›å½’ä»»åŠ¡çš„å ä½
                values.append(reg_data['RÂ²'])
                values.append(1 / (reg_data['Train_Time'] + 0.001))  # é¿å…é™¤é›¶
                values.append(0.7)  # ç¨³å®šæ€§å ä½
                values.append(reg_data['Composite_Score'])
            else:
                cls_data = self.classification_results[self.classification_results['Model'] == model_name].iloc[0]
                values.append(cls_data['Accuracy'])
                values.append(0.5)  # åˆ†ç±»ä»»åŠ¡çš„å ä½
                values.append(1 / (cls_data['Train_Time'] + 0.001))
                values.append(1 - cls_data.get('CV_Std', 0.1))  # ç¨³å®šæ€§
                values.append(cls_data['Composite_Score'])

            # å½’ä¸€åŒ–
            values = [v / max(1, max(values)) for v in values]
            values += values[:1]  # é—­åˆ

            # ç»˜åˆ¶
            ax.plot(angles, values, linewidth=2, linestyle='solid', label=model_name)
            ax.fill(angles, values, alpha=0.1)

        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0), fontsize=10)
        ax.set_title('æ¨¡å‹æ•ˆç‡é›·è¾¾å›¾', fontsize=14, fontweight='bold', pad=20)

    def _plot_improvement_summary(self, ax):
        """ç»˜åˆ¶æ”¹è¿›å¹…åº¦æ€»ç»“å›¾"""
        if self.regression_results is None or self.classification_results is None:
            return

        # è®¡ç®—æ”¹è¿›å¹…åº¦
        improvements = []
        labels = []

        # å›å½’ä»»åŠ¡MSEæ”¹è¿›
        baseline_reg_mse = self.regression_results[self.regression_results['Model'] == 'å†³ç­–æ ‘ (åŸºçº¿)']['MSE'].values[0]
        best_reg_mse = self.regression_results['MSE'].min()
        reg_improvement = (1 - best_reg_mse / baseline_reg_mse) * 100
        improvements.append(reg_improvement)
        labels.append('å›å½’MSEæ”¹è¿›')

        # å›å½’ä»»åŠ¡RÂ²æ”¹è¿›
        baseline_reg_r2 = self.regression_results[self.regression_results['Model'] == 'å†³ç­–æ ‘ (åŸºçº¿)']['RÂ²'].values[0]
        best_reg_r2 = self.regression_results['RÂ²'].max()
        reg_r2_improvement = (best_reg_r2 - baseline_reg_r2) * 100
        improvements.append(reg_r2_improvement)
        labels.append('å›å½’RÂ²æ”¹è¿›')

        # åˆ†ç±»ä»»åŠ¡å‡†ç¡®ç‡æ”¹è¿›
        baseline_cls_acc = \
        self.classification_results[self.classification_results['Model'] == 'å†³ç­–æ ‘ (åŸºçº¿)']['Accuracy'].values[0]
        best_cls_acc = self.classification_results['Accuracy'].max()
        cls_improvement = (best_cls_acc - baseline_cls_acc) * 100
        improvements.append(cls_improvement)
        labels.append('åˆ†ç±»å‡†ç¡®ç‡æ”¹è¿›')

        # ç»˜åˆ¶æŸ±çŠ¶å›¾
        bars = ax.bar(labels, improvements, color=['lightblue', 'lightgreen', 'lightcoral'], edgecolor='black')
        ax.set_ylabel('æ”¹è¿›å¹…åº¦ (%)', fontsize=12)
        ax.set_title('ç›¸å¯¹åŸºçº¿æ¨¡å‹çš„æ”¹è¿›å¹…åº¦', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3, axis='y')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, imp in zip(bars, improvements):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width() / 2, height + 0.5,
                    f'{imp:.1f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')

    def _add_text_summary(self, ax):
        """æ·»åŠ æ–‡æœ¬æ€»ç»“"""
        summary_text = """
        ç¬¬ä¸‰å¤©å­¦ä¹ æ ¸å¿ƒæ€»ç»“

        1. ğŸ“Š å›å½’ä»»åŠ¡è¡¨ç°
           â€¢ æœ€ä½³æ¨¡å‹: GBDT (æˆ‘ä»¬çš„å®ç°) - MSE: 2851.92, RÂ²: 0.4617
           â€¢ ç›¸å¯¹åŸºçº¿æ”¹è¿›: 19.1% (MSEé™ä½)
           â€¢ æˆ‘ä»¬çš„GBDTä¸sklearnæ€§èƒ½æ¥è¿‘ (å·®å¼‚<0.1%)

        2. ğŸ¯ åˆ†ç±»ä»»åŠ¡è¡¨ç°
           â€¢ æœ€ä½³æ¨¡å‹: AdaBoost (æˆ‘ä»¬çš„å®ç°) - å‡†ç¡®ç‡: 96.49%
           â€¢ æˆ‘ä»¬çš„AdaBoostä¼˜äºsklearnå®ç°
           â€¢ éšæœºæ£®æ—è¡¨ç°ç¨³å®šï¼Œè®­ç»ƒé€Ÿåº¦å¿«

        3. âš¡ è®­ç»ƒæ•ˆç‡
           â€¢ å†³ç­–æ ‘æœ€å¿« (0.002-0.005ç§’)
           â€¢ Baggingè®­ç»ƒå¿«ï¼Œæ”¯æŒå¹¶è¡Œ
           â€¢ Boostingç²¾åº¦é«˜ä½†è®­ç»ƒè¾ƒæ…¢

        4. ğŸ† å…³é”®æˆå°±
           â€¢ æˆåŠŸå®ç°AdaBoostå’ŒGBDTç®—æ³•
           â€¢ æ€§èƒ½è¾¾åˆ°/è¶…è¿‡sklearnå®˜æ–¹å®ç°
           â€¢ æ·±å…¥ç†è§£é›†æˆå­¦ä¹ åŸç†
           â€¢ å®Œæˆå®Œæ•´é¡¹ç›®å®è·µ

        5. ğŸ’¡ å®è·µå»ºè®®
           â€¢ è¿½æ±‚ç²¾åº¦: é€‰æ‹©GBDTï¼Œä»”ç»†è°ƒå‚
           â€¢ éœ€è¦é€Ÿåº¦: é€‰æ‹©éšæœºæ£®æ—æˆ–Bagging
           â€¢ å¤„ç†ä¸å¹³è¡¡: é€‰æ‹©AdaBoost
           â€¢ å¤§è§„æ¨¡æ•°æ®: ä½¿ç”¨å¹¶è¡ŒåŒ–Bagging
        """

        ax.text(0.02, 0.5, summary_text, fontsize=12, va='center',
                bbox=dict(boxstyle='round,pad=0.5', facecolor='lightyellow', alpha=0.9))
        ax.set_title('å®éªŒæ€»ç»“æŠ¥å‘Š', fontsize=16, fontweight='bold', loc='left')

    def generate_analysis_report(self):
        """ç”Ÿæˆå®Œæ•´çš„åˆ†ææŠ¥å‘Š"""
        print("=" * 60)
        print("ç”Ÿæˆç¬¬ä¸‰å¤©å®éªŒåˆ†ææŠ¥å‘Š")
        print("=" * 60)

        # åŠ è½½ç»“æœ
        self.load_results()

        # æ·±åº¦åˆ†æ
        reg_analysis = self.analyze_regression_results()
        cls_analysis = self.analyze_classification_results()

        # åˆ›å»ºå¯è§†åŒ–
        self.create_comprehensive_visualization()

        # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        os.makedirs(self.results_dir, exist_ok=True)
        report_path = f'{self.results_dir}/day3_analysis_report.txt'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("ç¬¬ä¸‰å¤©ï¼šé›†æˆå­¦ä¹ æ–¹æ³•å®éªŒåˆ†ææŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")

            f.write("1. å›å½’ä»»åŠ¡åˆ†æ\n")
            f.write("-" * 40 + "\n")
            f.write(f"æœ€ä½³MSEæ¨¡å‹: {reg_analysis['best_model']['by_mse']}\n")
            f.write(f"æœ€ä½³RÂ²æ¨¡å‹: {reg_analysis['best_model']['by_r2']}\n")
            f.write(f"ç»¼åˆæœ€ä½³æ¨¡å‹: {reg_analysis['best_model']['composite']}\n")
            f.write(f"MSEç›¸å¯¹åŸºçº¿æ”¹è¿›: {reg_analysis['improvements']['mse_improvement_percent']:.1f}%\n\n")

            f.write("2. åˆ†ç±»ä»»åŠ¡åˆ†æ\n")
            f.write("-" * 40 + "\n")
            f.write(f"æœ€ä½³å‡†ç¡®ç‡æ¨¡å‹: {cls_analysis['best_model']['by_accuracy']}\n")
            f.write(f"ç»¼åˆæœ€ä½³æ¨¡å‹: {cls_analysis['best_model']['by_composite']}\n\n")

            f.write("3. å…³é”®å‘ç°\n")
            f.write("-" * 40 + "\n")
            f.write("â€¢ Boostingæ–¹æ³•åœ¨ç²¾åº¦ä¸Šé€šå¸¸ä¼˜äºBagging\n")
            f.write("â€¢ éšæœºæ£®æ—æ˜¯ç²¾åº¦å’Œé€Ÿåº¦çš„è‰¯å¥½å¹³è¡¡\n")
            f.write("â€¢ æˆ‘ä»¬çš„å®ç°ä¸sklearnæ€§èƒ½ç›¸å½“\n")
            f.write("â€¢ ç±»åˆ«ä¸å¹³è¡¡æ˜¯åˆ†ç±»ä»»åŠ¡çš„ä¸»è¦æŒ‘æˆ˜\n\n")

            f.write("4. å®è·µå»ºè®®\n")
            f.write("-" * 40 + "\n")
            f.write("â€¢ é«˜ç²¾åº¦éœ€æ±‚: ä½¿ç”¨GBDTï¼Œä»”ç»†è°ƒå‚\n")
            f.write("â€¢ ç¨³å®šæ€§éœ€æ±‚: ä½¿ç”¨éšæœºæ£®æ—\n")
            f.write("â€¢ å¿«é€ŸåŸå‹: ä½¿ç”¨Bagging\n")
            f.write("â€¢ ä¸å¹³è¡¡æ•°æ®: ä½¿ç”¨AdaBoost\n")
            f.write("â€¢ å¤§è§„æ¨¡æ•°æ®: ä½¿ç”¨å¹¶è¡ŒåŒ–Bagging\n")

        print(f"\nâœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        print("âœ… ç»¼åˆå¯è§†åŒ–å·²ä¿å­˜åˆ°: ../results/figures/day3_comprehensive_analysis.png")

        return {
            'regression_analysis': reg_analysis,
            'classification_analysis': cls_analysis,
            'report_path': report_path
        }


# ä¸»ç¨‹åº
if __name__ == "__main__":
    # åˆ›å»ºåˆ†æå™¨
    analyzer = Day3ResultsAnalyzer()

    try:
        # ç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Š
        report = analyzer.generate_analysis_report()

        print("\n" + "=" * 60)
        print("åˆ†æå®Œæˆï¼")
        print("=" * 60)

    except FileNotFoundError as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        print("è¯·å…ˆè¿è¡Œå®éªŒä»£ç ç”Ÿæˆç»“æœæ–‡ä»¶")
    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()