📚 学习效果检测1  
1. AdaBoost中基学习器权重αₜ的计算公式是什么？当εₜ=0.45时，αₜ是多少？

2. 为什么AdaBoost要求基学习器的错误率εₜ < 0.5？
εₜ < 0.5 是“弱学习器”的定义（比随机猜测好）。只有满足此条件，αₜ才为正数，基学习器才能对集成模型产生正向贡献。
εₜ<0.5是弱学习器的基本要求。若εₜ>0.5，则αₜ为负值，该学习器会起反作用；εₜ=0.5时αₜ=0无贡献。算法通过调整权重分布保证该条件。
从指数损失最小化角度看，εₜ ≥ 0.5会导致损失函数无法继续下降
实际应用中，如果εₜ ≥ 0.5，通常会减少基学习器复杂度或增加数据量
3. 样本权重更新公式中，exp(-αₜ * yᵢ * hₜ(xᵢ))项的作用是什么？
正确分类样本(yᵢ·hₜ(xᵢ)=1)权重乘以exp(-αₜ)减小；错误分类样本(yᵢ·hₜ(xᵢ)=-1)权重乘以exp(αₜ)增大

4. AdaBoost的损失函数是什么？为什么使用这个损失函数？
指数损失函数L(y, f(x)) = exp(-y·f(x))。它是0-1损失的上界，连续可微便于优化，有闭式解
损失函数是指数损失：
L(y,f(x))=exp(−yf(x))。
主要因为：1）它是0-1损失的一个连续可微的凸上界，易于优化；2）在该损失下，前向分步算法每一步能得到闭式解（即αₜ的公式），推导优雅且高效。

5. 从偏差-方差角度，解释为什么Boosting容易过拟合？
Boosting通过串行修正错误不断降低偏差，可能导致过度拟合训练数据细节，使方差增大从而过拟合。
Boosting通过不断新增基学习器来修正前序错误，这强力降低了模型的偏差。
但随着迭代增加（基学习器增多），模型复杂度急剧上升，会开始拟合训练数据中的噪声和特殊细节，从而导致方差显著增大。 
当方差增大主导了泛化误差时，就会发生过拟合。
偏差-方差分解：总误差 = 偏差² + 方差 + 噪声误差
Boosting的影响：
降低偏差：每个基学习器专注于前序模型分错的样本；通过加权组合，逐步逼近真实函数；偏差随迭代次数增加而减小
增加方差：后续基学习器依赖前面的预测结果；错误会累积和放大；对噪声样本过度关注，导致模型过于复杂
过拟合的直观表现：训练误差持续下降，但验证误差先降后升；模型过于复杂，拟合了训练数据中的噪声；对微小变化敏感，泛化能力下降
防止过拟合的方法：早停法（Early Stopping）；收缩学习率（Shrinkage）；子采样（Subsampling）；正则化基学习器