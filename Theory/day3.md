📚 学习效果检测1  
1. AdaBoost中基学习器权重αₜ的计算公式是什么？当εₜ=0.45时，αₜ是多少？

2. 为什么AdaBoost要求基学习器的错误率εₜ < 0.5？
εₜ < 0.5 是“弱学习器”的定义（比随机猜测好）。只有满足此条件，αₜ才为正数，基学习器才能对集成模型产生正向贡献。
εₜ<0.5是弱学习器的基本要求。若εₜ>0.5，则αₜ为负值，该学习器会起反作用；εₜ=0.5时αₜ=0无贡献。算法通过调整权重分布保证该条件。

3. 样本权重更新公式中，exp(-αₜ * yᵢ * hₜ(xᵢ))项的作用是什么？
正确分类样本(yᵢ·hₜ(xᵢ)=1)权重乘以exp(-αₜ)减小；错误分类样本(yᵢ·hₜ(xᵢ)=-1)权重乘以exp(αₜ)增大

4. AdaBoost的损失函数是什么？为什么使用这个损失函数？
指数损失函数L(y, f(x)) = exp(-y·f(x))。它是0-1损失的上界，连续可微便于优化，有闭式解
损失函数是指数损失：
L(y,f(x))=exp(−yf(x))。
主要因为：1）它是0-1损失的一个连续可微的凸上界，易于优化；2）在该损失下，前向分步算法每一步能得到闭式解（即αₜ的公式），推导优雅且高效。

5. 从偏差-方差角度，解释为什么Boosting容易过拟合？
Boosting通过串行修正错误不断降低偏差，可能导致过度拟合训练数据细节，使方差增大从而过拟合。
Boosting通过不断新增基学习器来修正前序错误，这强力降低了模型的偏差。
但随着迭代增加（基学习器增多），模型复杂度急剧上升，会开始拟合训练数据中的噪声和特殊细节，从而导致方差显著增大。 
当方差增大主导了泛化误差时，就会发生过拟合。